Pipeline de AnÃ¡lisis de Tendencias en la Industria Espacial ğŸš€


* DescripciÃ³n del Proyecto
Este proyecto implementa un pipeline de datos utilizando la API de Spaceflight News para extraer, procesar y analizar informaciÃ³n sobre la industria espacial. Se emplea Google Cloud Composer (Airflow) para orquestar las tareas, BigQuery para almacenamiento y anÃ¡lisis, y Dataproc (Spark) para procesamiento distribuido.



* Arquitectura
ğŸ›° ExtracciÃ³n: Datos de artÃ­culos, blogs y reportes desde la API de Spaceflight News.

ğŸ›° Procesamiento: Limpieza, deduplicaciÃ³n y anÃ¡lisis con Apache Spark en Dataproc (Alternativas )
   -ğŸŸ¢ 1. Cloud Functions + Dataproc Jobs (Alternativa Ligera)
      âœ… Pros: No necesitas Airflow, Se ejecuta solo cuando hay nuevos archivos,Pago por uso (mÃ¡s eficiente que mantener Composer corriendo)
      â›” Contras: No tienes monitoreo y orquestaciÃ³n avanzada como en Airflow
   -ğŸ”µ 2. Cloud Run + Dataproc (Para Procesamiento Bajo Demanda)
      âœ… Pros: Se puede integrar con APIs y otros servicios,Mayor control sobre los triggers,Serverless y flexible
      â›” Contras: Requiere desplegar los servicios en Cloud Run
   -ğŸ”´ 3. BigQuery SQL (Si la TransformaciÃ³n es primaria), Se reemplaza Spark por BigQuery  usando SQL avanzado.  
      âœ… Pros: No se necesita Dataproc ni Airflow,BigQuery es mÃ¡s rÃ¡pido para consultas SQL sobre grandes volÃºmenes
      â›” Contras: No es tan flexible como Spark para procesos ETL mas avanzados. pero es una opcion por su integracion embebida con gemini.

ğŸ›° Almacenamiento: Google Cloud Storage (GCS) para datos crudos y BigQuery para anÃ¡lisis estructurado.
ğŸ›° OrquestaciÃ³n: Cloud Composer (Airflow) para la ejecuciÃ³n automatizada del pipeline.
ğŸ›° AnÃ¡lisis: Queries en BigQuery para identificar tendencias y fuentes mÃ¡s relevantes.

* TecnologÃ­as Utilizadas
ğŸ”¹ ExtracciÃ³n de datos: Python + Requests + API Spaceflight News
ğŸ”¹ Procesamiento: Apache Spark sobre Dataproc
ğŸ”¹ Almacenamiento: Google Cloud Storage (GCS) y BigQuery
ğŸ”¹ OrquestaciÃ³n: Cloud Composer (Airflow)
ğŸ”¹ AnÃ¡lisis SQL: Queries en BigQuery

* Flujo del Pipeline
1ï¸âƒ£ Ingesta: DAG de Airflow extrae datos de la API y los guarda en GCS.
2ï¸âƒ£ Procesamiento: Job en Dataproc (Spark) limpia, deduplica y clasifica los datos.
3ï¸âƒ£ Almacenamiento: Los datos transformados se almacenan en BigQuery.
4ï¸âƒ£ AnÃ¡lisis: Queries para tendencias por mes y ranking de fuentes influyentes.
5ï¸âƒ£ AutomatizaciÃ³n: Airflow ejecuta el flujo de trabajo diariamente.

* InstalaciÃ³n y ConfiguraciÃ³n
1. Clonar el Repositorio
bash
Copiar
Editar
git clone https://github.com/tuusuario/spaceflight-pipeline.git
cd spaceflight-pipeline
2. Configurar Variables de Entorno
bash
Copiar
Editar
export PROJECT_ID="tu-proyecto-gcp"
export BUCKET_NAME="tu-bucket-gcs"
export BIGQUERY_DATASET="tu-dataset-bigquery"
export API_URL="https://api.spaceflightnewsapi.net/v4"
3. Implementar Airflow en Cloud Composer
Crear un entorno de Cloud Composer en GCP:
bash
Copiar
Editar
gcloud composer environments create spaceflight-pipeline \
  --location us-central1 \
  --image-version composer-2-airflow-2
Configurar el DAG en Airflow:
Subir el archivo spaceflight_dag.py al bucket de Cloud Composer:
bash
Copiar
Editar
gsutil cp dags/spaceflight_dag.py gs://tu-bucket-composer/dags/
Verificar la ejecuciÃ³n en la interfaz de Cloud Composer.
4. Ejecutar el Pipeline Manualmente
bash
Copiar
Editar
gcloud composer environments run spaceflight-pipeline \
    --location us-central1 trigger_dag -- spaceflight_dag
Consultas SQL en BigQuery

Ejemplo de consulta para tendencias de temas por mes:

sql
Copiar
Editar
SELECT topic, COUNT(*) as cantidad, DATE_TRUNC(published_at, MONTH) as mes
FROM `tu-proyecto-gcp.tu-dataset.fact_article`
GROUP BY topic, mes
ORDER BY mes DESC, cantidad DESC;

Tareas Pendientes
â˜‘ï¸ Optimizar particionamiento de BigQuery para mejorar consultas.
â˜‘ï¸ Implementar dashboard en Looker Studio.
â˜‘ï¸ Agregar mÃ¡s mÃ©tricas para evaluar impacto de noticias.

ğŸ“Œ Contacto: juancarloscm@yahoo.com
