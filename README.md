#  Pipeline de Analisis de Tendencias en la Industria Espacial ğŸš€
# ğŸš€ Proyecto: ETL y AnÃ¡lisis de Noticias en GCP

## ğŸ“Œ Descripcion
Este proyecto implementa un pipeline de **ETL (Extract, Transform, Load)** en **Google Cloud Platform (GCP)** para extraer datos de la API de **Spaceflight News**, transformarlos con **Apache Spark en Dataproc**, y almacenarlos en **Google BigQuery** para anÃ¡lisis y visualizaciÃ³n.

## âš™ï¸ Tecnologias Utilizadas
- **Google Cloud Composer (Airflow)** - OrquestaciÃ³n del pipeline.
- **Google Cloud Storage (GCS)** - Almacenamiento intermedio de datos.
- **Google BigQuery** - Data Warehouse para anÃ¡lisis y reportes.
- **Google Dataproc (Spark)** - TransformaciÃ³n y procesamiento de datos.
- **Looker Studio** - VisualizaciÃ³n de datos.

## ğŸ“ Estructura del Proyecto
```
â”œâ”€â”€ Dags/
â”‚   â”œâ”€â”€ Dag_blogs_Biquery_Dinamico # etl_almacen_datos_noticias.py-DAG principal en Airflow
â”‚â”€â”€ Data_Warehouse_Bigquery/
â”‚   â”œâ”€â”€ Fuentes_Noticias_mas_Influyentes.sql  
â”‚   â”œâ”€â”€ Tablas.sql  # sql creacion de tablas 
â”‚   â”œâ”€â”€ Tendencias_Temas_mes.sql  # sql Tendencias
â”‚â”€â”€ sql/
â”‚   â”œâ”€â”€ Relacion_tablas.sql
â”‚   â”œâ”€â”€ dim_fuentes_noticias.sql
â”‚   â”œâ”€â”€ dim_temas.sql
â”‚   â”œâ”€â”€ noticias_procesadas.sql
â”‚â”€â”€ scripts/
â”‚   â”œâ”€â”€ procesamiento_spark.py  # Transformaciones con Spark en Dataproc
â”‚â”€â”€ test_Unitarios/
â”‚   â”œâ”€â”€ test_conectividad_bigquery.py  # Test de integridad del DAG
â”‚   â”œâ”€â”€ test_dag.py  # Test de validaciÃ³n en BigQuery
â”‚â”€â”€ arquitecturas/
â”‚   â”œâ”€â”€ Parte1_Arquitectura_Pipeline
â”‚   â”œâ”€â”€ test_bigquery.py  # Test de validaciÃ³n en BigQuery
â”‚â”€â”€ procesamiento/
â”‚   â”œâ”€â”€ comandos.txt  #
â”‚   â”œâ”€â”€ procesamiento_spark.py  #
â”‚   â”œâ”€â”€ procesamiento_spark_funciones.py  #
â”‚   â”œâ”€â”€ procesamiento_spark_optimizado.py  #
â”‚â”€â”€ README.md  # DocumentaciÃ³n
```

## ğŸš€ Flujo del Pipeline
1ï¸âƒ£ **ExtracciÃ³n de Datos**: Se extraen noticias desde la API de **Spaceflight News**, manejando paginaciÃ³n y rate limits.
2ï¸âƒ£ **Almacenamiento en GCS**: Los datos se guardan en formato **JSON y Parquet** en Google Cloud Storage.
3ï¸âƒ£ **Procesamiento en Dataproc (Spark)**: Limpieza, deduplicaciÃ³n y anÃ¡lisis de contenido y tendencias.
4ï¸âƒ£ **Carga en BigQuery**: Se insertan datos normalizados en un modelo dimensional.
5ï¸âƒ£ **AnÃ¡lisis SQL**: Se ejecutan consultas optimizadas para tendencias y reportes.
6ï¸âƒ£ **VisualizaciÃ³n en Looker Studio**: Se crean dashboards para anÃ¡lisis de datos.

## ğŸ›  ConfiguraciÃ³n y Despliegue
### 1ï¸âƒ£ Subir el DAG a Composer
```sh
gsutil cp dags/etl_almacen_datos_noticias.py gs://us-central1-flujotransacion-9cfbfa36-bucket/dags/
```

### 2ï¸âƒ£ Subir Script de Spark a GCS
```sh
gsutil cp scripts/procesamiento_spark.py gs://us-central1-flujotransacion-9cfbfa36-bucket/scripts/
```

### 3ï¸âƒ£ Reiniciar Airflow para Aplicar Cambios
```sh
gcloud composer environments restart-web-server flujotransacional --location us-central1
```

### 4ï¸âƒ£ Ejecutar el DAG en Airflow
1. Ir a **Composer â†’ Abrir Airflow**  
2. Activar y Ejecutar el DAG **`etl_almacen_datos_noticias`**  
3. Monitorear la ejecuciÃ³n en **BigQuery**  

## ğŸ§ª Tests Unitarios
Ejecutar pruebas en Airflow y BigQuery:
```sh
pytest tests/
```

## ğŸ“Š AnÃ¡lisis SQL
### ğŸ”¹ **Tendencias de temas por mes**
```sql
SELECT FORMAT_DATE('%Y-%m', fecha_publicacion) AS mes, nombre, COUNT(*) AS total
FROM `analitica-contact-center-dev.Entorno_Pruebas_modelo.fact_articulos`
JOIN `analitica-contact-center-dev.Entorno_Pruebas_modelo.dim_temas`
ON fact_articulos.topic_id = dim_temas.topic_id
GROUP BY mes, nombre ORDER BY mes DESC, total DESC;
```

### ğŸ”¹ **Fuentes de noticias mas influyentes**
```sql
SELECT f.nombre AS fuente, COUNT(a.article_id) AS total_articulos,
       SUM(a.visitas) AS total_visitas, SUM(a.compartidos) AS total_compartidos,
       (SUM(a.visitas) + SUM(a.compartidos)) AS impacto_total
FROM `analitica-contact-center-dev.Entorno_Pruebas_modelo.fact_articulos` a
JOIN `analitica-contact-center-dev.Entorno_Pruebas_modelo.dim_fuentes_noticias` f
ON a.source_id = f.source_id
GROUP BY fuente
ORDER BY impacto_total DESC
LIMIT 10;
```

## ğŸ“ˆ VisualizaciÃ³n en Looker Studio
Conectar **BigQuery** con **Looker Studio** para crear un dashboards interactivo y visualizar tendencias en los datos.

## ğŸ“Œ ConclusiÃ³n
âœ” **Pipeline optimizado con particionamiento y clustering en BigQuery**  
âœ” **Procesamiento escalable en Dataproc con Apache Spark**  
âœ” **OrquestaciÃ³n eficiente con Airflow en Cloud Composer**  
âœ” **VisualizaciÃ³n intuitiva en Looker Studio**  





